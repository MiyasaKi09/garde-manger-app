#!/usr/bin/env python3
"""
Analyse de la qualitÃ© et des doublons dans la base de recettes
DÃ©tecte les recettes redondantes, trop gÃ©nÃ©riques ou inutiles
"""

import csv
from collections import defaultdict
import re
from difflib import SequenceMatcher

def normalize_name(name):
    """Normalise un nom pour la comparaison"""
    # Minuscules
    name = name.lower()
    # Supprimer accents (simple)
    replacements = {
        'Ã©': 'e', 'Ã¨': 'e', 'Ãª': 'e', 'Ã«': 'e',
        'Ã ': 'a', 'Ã¢': 'a', 'Ã¤': 'a',
        'Ã´': 'o', 'Ã¶': 'o',
        'Ã»': 'u', 'Ã¼': 'u', 'Ã¹': 'u',
        'Ã®': 'i', 'Ã¯': 'i',
        'Ã§': 'c',
        'Å“': 'oe'
    }
    for old, new in replacements.items():
        name = name.replace(old, new)
    
    # Normaliser espaces
    name = ' '.join(name.split())
    
    return name

def similarity(s1, s2):
    """Calcule la similaritÃ© entre deux chaÃ®nes (0-1)"""
    return SequenceMatcher(None, s1, s2).ratio()

def load_all_recipes():
    """Charge toutes les recettes depuis les 3 batches"""
    recipes = []
    
    for batch_file in ['recipes_300.csv', 'recipes_300_batch2.csv', 'recipes_batch3_remaining.csv']:
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    recipes.append({
                        'id': row['id'],
                        'name': row['name'],
                        'role': row['role'],
                        'name_normalized': normalize_name(row['name'])
                    })
        except FileNotFoundError:
            print(f"âš ï¸  Fichier {batch_file} non trouvÃ©")
    
    return recipes

def analyze_duplicates(recipes):
    """DÃ©tecte les doublons exacts et quasi-identiques"""
    print("\n" + "="*80)
    print("ğŸ” ANALYSE DES DOUBLONS")
    print("="*80)
    
    # Doublons exacts (nom normalisÃ© identique)
    exact_duplicates = defaultdict(list)
    for recipe in recipes:
        exact_duplicates[recipe['name_normalized']].append(recipe)
    
    exact_count = 0
    for name_norm, dups in sorted(exact_duplicates.items()):
        if len(dups) > 1:
            exact_count += len(dups) - 1
            print(f"\nâŒ DOUBLON EXACT ({len(dups)} recettes) :")
            for dup in dups:
                print(f"   [{dup['id']:4s}] {dup['name']:60s} ({dup['role']})")
    
    if exact_count == 0:
        print("âœ… Aucun doublon exact trouvÃ©")
    else:
        print(f"\nğŸ“Š Total: {exact_count} doublons exacts")
    
    # Quasi-doublons (similaritÃ© > 90%)
    print("\n" + "="*80)
    print("ğŸ” QUASI-DOUBLONS (similaritÃ© > 90%)")
    print("="*80)
    
    quasi_duplicates = []
    for i, recipe1 in enumerate(recipes):
        for recipe2 in recipes[i+1:]:
            sim = similarity(recipe1['name_normalized'], recipe2['name_normalized'])
            if sim > 0.90 and sim < 1.0:  # Pas 100% (dÃ©jÃ  traitÃ©)
                quasi_duplicates.append((recipe1, recipe2, sim))
    
    quasi_duplicates.sort(key=lambda x: -x[2])
    
    if quasi_duplicates:
        for recipe1, recipe2, sim in quasi_duplicates[:50]:  # Top 50
            print(f"\nâš ï¸  SimilaritÃ© {sim:.1%} :")
            print(f"   [{recipe1['id']:4s}] {recipe1['name']}")
            print(f"   [{recipe2['id']:4s}] {recipe2['name']}")
    else:
        print("âœ… Aucun quasi-doublon trouvÃ©")
    
    print(f"\nğŸ“Š Total: {len(quasi_duplicates)} paires quasi-identiques")
    
    return exact_count, len(quasi_duplicates)

def analyze_generic_recipes(recipes):
    """DÃ©tecte les recettes trop gÃ©nÃ©riques"""
    print("\n" + "="*80)
    print("ğŸ” RECETTES TROP GÃ‰NÃ‰RIQUES")
    print("="*80)
    
    generic_patterns = [
        # Motifs gÃ©nÃ©riques Ã  dÃ©tecter
        (r'^(boeuf|bÅ“uf|veau|agneau|porc|poulet|dinde|canard|saumon|thon|cabillaud) (aux?|au|Ã  la|Ã  l\') (lÃ©gumes?|herbes?|Ã©pices?|sauce|tomates?)$', 
         "Trop vague - manque de spÃ©cificitÃ©"),
        (r'^(boeuf|bÅ“uf|veau|agneau|porc|poulet|dinde|canard) grillÃ©$',
         "Trop simple - manque d'originalitÃ©"),
        (r'^(boeuf|bÅ“uf|veau|agneau|porc|poulet|dinde|canard) rÃ´ti$',
         "Trop simple - manque d'originalitÃ©"),
        (r'^(boeuf|bÅ“uf|veau|agneau|porc|poulet|dinde) sauce .*$',
         "GÃ©nÃ©rique - quelle sauce ?"),
        (r'^potage aux? .*$',
         "GÃ©nÃ©rique - tous les potages se ressemblent"),
        (r'^salade de? .*$',
         "Peut Ãªtre gÃ©nÃ©rique"),
    ]
    
    generic_recipes = []
    
    for recipe in recipes:
        name_norm = recipe['name_normalized']
        for pattern, reason in generic_patterns:
            if re.match(pattern, name_norm):
                generic_recipes.append((recipe, reason))
                break
    
    if generic_recipes:
        # Grouper par raison
        by_reason = defaultdict(list)
        for recipe, reason in generic_recipes:
            by_reason[reason].append(recipe)
        
        for reason, recs in sorted(by_reason.items()):
            print(f"\nâš ï¸  {reason} ({len(recs)} recettes) :")
            for recipe in sorted(recs, key=lambda x: x['name'])[:20]:  # Max 20 exemples
                print(f"   [{recipe['id']:4s}] {recipe['name']:60s} ({recipe['role']})")
            if len(recs) > 20:
                print(f"   ... et {len(recs) - 20} autres")
    else:
        print("âœ… Pas de recettes manifestement trop gÃ©nÃ©riques")
    
    print(f"\nğŸ“Š Total: {len(generic_recipes)} recettes potentiellement trop gÃ©nÃ©riques")
    
    return len(generic_recipes)

def analyze_micro_variations(recipes):
    """DÃ©tecte les micro-variations (ex: poulet grillÃ©, poulet grillÃ© aux herbes, etc.)"""
    print("\n" + "="*80)
    print("ğŸ” MICRO-VARIATIONS (variations mineures d'un mÃªme plat)")
    print("="*80)
    
    # Grouper par base de nom
    groups = defaultdict(list)
    
    for recipe in recipes:
        # Extraire la base (avant les dÃ©tails)
        name_norm = recipe['name_normalized']
        
        # Patterns pour extraire la base
        base = name_norm
        
        # Retirer les dÃ©tails aprÃ¨s "aux, au, Ã  la, avec, sauce, marinÃ©, glacÃ©, etc."
        for sep in [' aux ', ' au ', ' Ã  la ', ' Ã  l\'', ' avec ', ' et ', ' sauce ', ' marine', ' glace', ' roti', ' grille', ' pane', ' frit']:
            if sep in base:
                base = base.split(sep)[0]
                break
        
        groups[base].append(recipe)
    
    # Identifier les groupes avec beaucoup de variations
    micro_variations = []
    for base, recs in groups.items():
        if len(recs) >= 5:  # 5+ variations = suspect
            micro_variations.append((base, recs))
    
    micro_variations.sort(key=lambda x: -len(x[1]))
    
    if micro_variations:
        print(f"\n{len(micro_variations)} bases avec beaucoup de variations :\n")
        
        for base, recs in micro_variations[:30]:  # Top 30
            print(f"\nğŸ“‹ Base: '{base}' ({len(recs)} variations)")
            for recipe in sorted(recs, key=lambda x: x['name'])[:10]:
                print(f"   [{recipe['id']:4s}] {recipe['name']}")
            if len(recs) > 10:
                print(f"   ... et {len(recs) - 10} autres variations")
    else:
        print("âœ… Pas de groupes avec trop de micro-variations")
    
    total_variations = sum(len(recs) for _, recs in micro_variations)
    print(f"\nğŸ“Š Total: {len(micro_variations)} groupes avec {total_variations} recettes")
    
    return micro_variations

def analyze_usefulness(recipes):
    """Analyse l'utilitÃ© des recettes"""
    print("\n" + "="*80)
    print("ğŸ” ANALYSE DE L'UTILITÃ‰")
    print("="*80)
    
    # Recettes suspects
    suspicious = []
    
    for recipe in recipes:
        name = recipe['name'].lower()
        
        # CritÃ¨res de suspicion
        reasons = []
        
        # Trop court (manque de dÃ©tail)
        if len(recipe['name']) < 15:
            reasons.append("Nom trop court/vague")
        
        # Que des ingrÃ©dients de base
        if any(pattern in name for pattern in [
            'bÅ“uf aux', 'veau aux', 'agneau aux', 'porc aux',
            'poulet aux', 'dinde aux', 'canard aux'
        ]):
            if not any(specific in name for specific in [
                'curry', 'moutarde', 'miel', 'vin', 'sauce',
                'braisÃ©', 'confit', 'rÃ´ti', 'grillÃ©'
            ]):
                reasons.append("IngrÃ©dient + accompagnement basique")
        
        # Recettes "froid" (peu utiles dans une app de cuisine)
        if 'froid' in name and recipe['role'] != 'ENTREE':
            reasons.append("Recette 'froid' redondante")
        
        if reasons:
            suspicious.append((recipe, reasons))
    
    if suspicious:
        # Grouper par raison
        by_reason = defaultdict(list)
        for recipe, reasons in suspicious:
            for reason in reasons:
                by_reason[reason].append(recipe)
        
        for reason, recs in sorted(by_reason.items()):
            print(f"\nâš ï¸  {reason} ({len(recs)} recettes) :")
            for recipe in sorted(recs, key=lambda x: x['name'])[:15]:
                print(f"   [{recipe['id']:4s}] {recipe['name']:60s} ({recipe['role']})")
            if len(recs) > 15:
                print(f"   ... et {len(recs) - 15} autres")
    
    print(f"\nğŸ“Š Total: {len(suspicious)} recettes potentiellement peu utiles")
    
    return len(suspicious)

def generate_recommendations(recipes, exact_dups, quasi_dups, generic_count, micro_variations, suspicious_count):
    """GÃ©nÃ¨re les recommandations finales"""
    print("\n" + "="*80)
    print("ğŸ’¡ RECOMMANDATIONS")
    print("="*80)
    
    print(f"\nğŸ“Š RÃ©capitulatif:")
    print(f"   â€¢ Total recettes: {len(recipes)}")
    print(f"   â€¢ Doublons exacts: {exact_dups}")
    print(f"   â€¢ Quasi-doublons: {quasi_dups}")
    print(f"   â€¢ Recettes gÃ©nÃ©riques: {generic_count}")
    print(f"   â€¢ Groupes avec micro-variations: {len(micro_variations)}")
    print(f"   â€¢ Recettes peu utiles: {suspicious_count}")
    
    # Calculer le nombre estimÃ© de recettes Ã  nettoyer
    to_clean = exact_dups + (quasi_dups // 2) + (generic_count // 3) + suspicious_count
    
    print(f"\nğŸ¯ Actions recommandÃ©es:")
    print(f"   1. Supprimer les {exact_dups} doublons exacts")
    print(f"   2. Fusionner ~{quasi_dups // 2} quasi-doublons")
    print(f"   3. Enrichir ou supprimer ~{generic_count // 3} recettes gÃ©nÃ©riques")
    print(f"   4. Consolider les groupes avec trop de micro-variations")
    print(f"   5. Supprimer les recettes peu utiles")
    
    print(f"\nğŸ“‰ Nettoyage estimÃ©: {to_clean} recettes Ã  rÃ©viser ({to_clean * 100 // len(recipes)}%)")
    print(f"   Base optimale: ~{len(recipes) - to_clean} recettes de qualitÃ©")
    
    return to_clean

def main():
    print("ğŸ” ANALYSE QUALITÃ‰ DE LA BASE DE RECETTES")
    print("="*80)
    
    recipes = load_all_recipes()
    print(f"\nğŸ“– {len(recipes)} recettes chargÃ©es")
    
    # Analyses
    exact_dups, quasi_dups = analyze_duplicates(recipes)
    generic_count = analyze_generic_recipes(recipes)
    micro_variations = analyze_micro_variations(recipes)
    suspicious_count = analyze_usefulness(recipes)
    
    # Recommandations
    to_clean = generate_recommendations(
        recipes, exact_dups, quasi_dups, 
        generic_count, micro_variations, suspicious_count
    )
    
    print("\nâœ… Analyse terminÃ©e !")
    print("\nVoulez-vous gÃ©nÃ©rer un fichier CSV avec les recettes Ã  rÃ©viser ? (O/N)")

if __name__ == '__main__':
    main()
